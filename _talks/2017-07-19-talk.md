---
title: "Metric Perspective of Stochastic Optimizers"
collection: talks
type: "Research Seminar"
permalink: /talks/2017-07-19-talk
venue: "Keio University Research Seminar"
date: 2017-07-19
location: "Tokyo, Japan"
---

In this talk, I explain several major stochastic optimizers from the perspective of the metric, that is the definition of the parameter space of the model.
This talk covers algorithms such as 
- Quasi-Newton Method Type
    * Finite-Difference Method: SGD-QN, AdaDelta, VSGD
    * Extended Gauss-Newton: KSD, SMD, HF
    * LBFGS: Stochastic LBFGS, RES
- Natural Gradient Type: Natural Gradient, TONGA
- Root Mean Square Type: AdaGrad, RMSProp, Adam

<iframe src="//https://github.com/tanyaroosta/tanyaroosta.github.io/blob/master/_talks/Berkeley_keynote_2022.pdf" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//https://github.com/tanyaroosta/tanyaroosta.github.io/blob/master/_talks/Berkeley_keynote_2022.pdf" title="2017-07, Keynote" target="_blank">2017-07, Research Seminar at Keio University, Metric Perspective of Stochastic Optimizers</a> </strong> from <strong><a href="https://github.com/tanyaroosta/tanyaroosta.github.io/blob/master/_talks/Berkeley_keynote_2022.pdf" target="_blank">asahiushio1</a></strong> </div>
